{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATE A MODEL THAT CAN PREDICT FUTURE KALSHI PRICES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take each market in each day of data. Starting at 9:30a, take 3 hours of data. This will be the input data. Then take the next half hour for output data. Then slide the window by 30 minutes. We will end up with 5 slices per day. Return two arrays, one with the five input slices and one with the five output slices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = [[i+1, i+1] for i in range(390)]\n",
    "df = pd.DataFrame(data, columns=['Column1', 'Column2'])\n",
    "\n",
    "#takes in a dataframe and returns input/output pairs for training/testing\n",
    "def split_a_market(market_df, window_size=210, stride=30):\n",
    "    input_array = []\n",
    "    output_array = []\n",
    "    \n",
    "    entries = 0\n",
    "    for i in range(0, len(market_df), stride):\n",
    "        if entries == 5:\n",
    "            break\n",
    "        \n",
    "        window_start = i\n",
    "        window_end = i + window_size\n",
    "        \n",
    "        window_data = market_df.iloc[window_start:window_end]\n",
    "    \n",
    "        inputs = window_data.iloc[:180].values\n",
    "        outputs = window_data.iloc[180:].values\n",
    "        \n",
    "        input_array.append(inputs)\n",
    "        output_array.append(outputs)\n",
    "        \n",
    "        entries += 1\n",
    "    \n",
    "    input_array = np.array(input_array)\n",
    "    output_array = np.array(output_array)\n",
    "    \n",
    "    return input_array, output_array\n",
    "\n",
    "# split_a_market(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take each csv and run split_a_market on it to get training and testing splits for that day. Then add those to the broader train and test arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2250, 180, 5), (2250, 30, 5))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "filespath = '../data_storage/ml_training_data/combined_data'\n",
    "file_list = ['../data_storage/ml_training_data/combined_data/' + str(file) for file in os.listdir(filespath) if os.path.isfile(os.path.join(filespath, file))]\n",
    "\n",
    "x = np.empty((0, 180, 5))\n",
    "y = np.empty((0, 30, 5))\n",
    "\n",
    "for fp in file_list:\n",
    "    try:\n",
    "        df = pd.read_csv(fp)\n",
    "        \n",
    "        def time_to_numerical(time_str):\n",
    "            hours, minutes = map(int, time_str.split(':'))\n",
    "            return hours + minutes / 60.0\n",
    "\n",
    "        df['time'] = df['time'].apply(time_to_numerical)\n",
    "        inputs, outputs = split_a_market(df)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    for row in inputs:\n",
    "        x = np.append(x, [row], axis=0)\n",
    "    for row in outputs:\n",
    "        y = np.append(y, [row], axis=0)\n",
    "    \n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1800, 180, 5)\n",
      "X_test shape: (450, 180, 5)\n",
      "Y_train shape: (1800, 30, 5)\n",
      "Y_test shape: (450, 30, 5)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "X_input = x \n",
    "Y_output = y\n",
    "\n",
    "# Reshape the input and output arrays into 2D arrays\n",
    "X_input_flat = X_input.reshape((X_input.shape[0], -1))  # Shape (2250, 180*5)\n",
    "Y_output_flat = Y_output.reshape((Y_output.shape[0], -1))  # Shape (2250, 30*5)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_input_flat, Y_output_flat, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape back to original shape\n",
    "X_train = X_train.reshape((X_train.shape[0], X_input.shape[1], X_input.shape[2]))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_input.shape[1], X_input.shape[2]))\n",
    "Y_train = Y_train.reshape((Y_train.shape[0], Y_output.shape[1], Y_output.shape[2]))\n",
    "Y_test = Y_test.reshape((Y_test.shape[0], Y_output.shape[1], Y_output.shape[2]))\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"Y_train shape:\", Y_train.shape)\n",
    "print(\"Y_test shape:\", Y_test.shape)\n",
    "\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "Y_train = Y_train.astype(np.float32)\n",
    "Y_test = Y_test.astype(np.float32)\n",
    "\n",
    "X_train_tensor = torch.Tensor(X_train)\n",
    "X_test_tensor = torch.Tensor(X_test)\n",
    "Y_train_tensor = torch.Tensor(Y_train)\n",
    "Y_test_tensor = torch.Tensor(Y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Shape: torch.Size([1800, 180, 5]) torch.Size([1800, 30, 5])\n",
      "Testing Shape: torch.Size([450, 180, 5]) torch.Size([450, 30, 5])\n"
     ]
    }
   ],
   "source": [
    "X_train_tensor = torch.reshape(X_train_tensor,   \n",
    "                                      (X_train_tensor.shape[0], 180, \n",
    "                                       X_train_tensor.shape[2]))\n",
    "X_test_tensor = torch.reshape(X_test_tensor,  \n",
    "                                     (X_test_tensor.shape[0], 180, \n",
    "                                      X_test_tensor.shape[2])) \n",
    "\n",
    "print(\"Training Shape:\", X_train_tensor.shape, Y_train_tensor.shape)\n",
    "print(\"Testing Shape:\", X_test_tensor.shape, Y_test_tensor.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 5220056.5\n",
      "Epoch [2/100], Loss: 5219925.0\n",
      "Epoch [3/100], Loss: 5219790.0\n",
      "Epoch [4/100], Loss: 5219664.0\n",
      "Epoch [5/100], Loss: 5219536.5\n",
      "Epoch [6/100], Loss: 5219401.5\n",
      "Epoch [7/100], Loss: 5219254.0\n",
      "Epoch [8/100], Loss: 5219050.5\n",
      "Epoch [9/100], Loss: 5218862.0\n",
      "Epoch [10/100], Loss: 5218679.5\n",
      "Epoch [11/100], Loss: 5218479.0\n",
      "Epoch [12/100], Loss: 5218261.0\n",
      "Epoch [13/100], Loss: 5218024.0\n",
      "Epoch [14/100], Loss: 5217769.5\n",
      "Epoch [15/100], Loss: 5217499.5\n",
      "Epoch [16/100], Loss: 5217216.0\n",
      "Epoch [17/100], Loss: 5216925.0\n",
      "Epoch [18/100], Loss: 5216625.5\n",
      "Epoch [19/100], Loss: 5216323.0\n",
      "Epoch [20/100], Loss: 5216021.5\n",
      "Epoch [21/100], Loss: 5215723.0\n",
      "Epoch [22/100], Loss: 5215429.5\n",
      "Epoch [23/100], Loss: 5215142.0\n",
      "Epoch [24/100], Loss: 5214860.0\n",
      "Epoch [25/100], Loss: 5214583.5\n",
      "Epoch [26/100], Loss: 5214310.5\n",
      "Epoch [27/100], Loss: 5214040.0\n",
      "Epoch [28/100], Loss: 5213771.0\n",
      "Epoch [29/100], Loss: 5213502.5\n",
      "Epoch [30/100], Loss: 5213235.0\n",
      "Epoch [31/100], Loss: 5212966.5\n",
      "Epoch [32/100], Loss: 5212699.0\n",
      "Epoch [33/100], Loss: 5212432.0\n",
      "Epoch [34/100], Loss: 5212165.0\n",
      "Epoch [35/100], Loss: 5211899.0\n",
      "Epoch [36/100], Loss: 5211635.5\n",
      "Epoch [37/100], Loss: 5211372.5\n",
      "Epoch [38/100], Loss: 5211112.0\n",
      "Epoch [39/100], Loss: 5210853.0\n",
      "Epoch [40/100], Loss: 5210595.0\n",
      "Epoch [41/100], Loss: 5210340.0\n",
      "Epoch [42/100], Loss: 5210088.0\n",
      "Epoch [43/100], Loss: 5209837.5\n",
      "Epoch [44/100], Loss: 5209590.5\n",
      "Epoch [45/100], Loss: 5209346.0\n",
      "Epoch [46/100], Loss: 5209104.0\n",
      "Epoch [47/100], Loss: 5208865.5\n",
      "Epoch [48/100], Loss: 5208630.0\n",
      "Epoch [49/100], Loss: 5208395.5\n",
      "Epoch [50/100], Loss: 5208166.5\n",
      "Epoch [51/100], Loss: 5207939.5\n",
      "Epoch [52/100], Loss: 5207715.0\n",
      "Epoch [53/100], Loss: 5207493.5\n",
      "Epoch [54/100], Loss: 5207276.0\n",
      "Epoch [55/100], Loss: 5207061.5\n",
      "Epoch [56/100], Loss: 5206850.5\n",
      "Epoch [57/100], Loss: 5206642.0\n",
      "Epoch [58/100], Loss: 5206437.0\n",
      "Epoch [59/100], Loss: 5206235.0\n",
      "Epoch [60/100], Loss: 5206037.0\n",
      "Epoch [61/100], Loss: 5205841.0\n",
      "Epoch [62/100], Loss: 5205649.0\n",
      "Epoch [63/100], Loss: 5205458.0\n",
      "Epoch [64/100], Loss: 5205269.0\n",
      "Epoch [65/100], Loss: 5205082.5\n",
      "Epoch [66/100], Loss: 5204898.0\n",
      "Epoch [67/100], Loss: 5204714.5\n",
      "Epoch [68/100], Loss: 5204532.0\n",
      "Epoch [69/100], Loss: 5204351.5\n",
      "Epoch [70/100], Loss: 5204172.0\n",
      "Epoch [71/100], Loss: 5203992.0\n",
      "Epoch [72/100], Loss: 5203813.5\n",
      "Epoch [73/100], Loss: 5203636.0\n",
      "Epoch [74/100], Loss: 5203458.5\n",
      "Epoch [75/100], Loss: 5203280.5\n",
      "Epoch [76/100], Loss: 5203104.5\n",
      "Epoch [77/100], Loss: 5202928.5\n",
      "Epoch [78/100], Loss: 5202754.5\n",
      "Epoch [79/100], Loss: 5202580.5\n",
      "Epoch [80/100], Loss: 5202407.0\n",
      "Epoch [81/100], Loss: 5202234.0\n",
      "Epoch [82/100], Loss: 5202063.0\n",
      "Epoch [83/100], Loss: 5201892.5\n",
      "Epoch [84/100], Loss: 5201722.5\n",
      "Epoch [85/100], Loss: 5201552.0\n",
      "Epoch [86/100], Loss: 5201383.5\n",
      "Epoch [87/100], Loss: 5201214.5\n",
      "Epoch [88/100], Loss: 5201047.0\n",
      "Epoch [89/100], Loss: 5200880.0\n",
      "Epoch [90/100], Loss: 5200713.0\n",
      "Epoch [91/100], Loss: 5200547.5\n",
      "Epoch [92/100], Loss: 5200381.0\n",
      "Epoch [93/100], Loss: 5200217.0\n",
      "Epoch [94/100], Loss: 5200053.0\n",
      "Epoch [95/100], Loss: 5199888.5\n",
      "Epoch [96/100], Loss: 5199725.0\n",
      "Epoch [97/100], Loss: 5199561.5\n",
      "Epoch [98/100], Loss: 5199399.5\n",
      "Epoch [99/100], Loss: 5199237.5\n",
      "Epoch [100/100], Loss: 5199075.5\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the LSTM model\n",
    "class FinancialLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(FinancialLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -30:, :])  # Output the next 30 minutes\n",
    "        return out\n",
    "\n",
    "# Prepare your financial time series data\n",
    "# Example: financial_data = ... (prepare your data here)\n",
    "\n",
    "# Define hyperparameters\n",
    "input_size = 5  # 5 features per minute\n",
    "hidden_size = 64\n",
    "num_layers = 2\n",
    "output_size = 5  # 5 features per minute for the next 30 minutes\n",
    "\n",
    "# Create the LSTM model\n",
    "model = FinancialLSTM(input_size, hidden_size, num_layers, output_size)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(X_train_tensor)\n",
    "    \n",
    "    # Compute the loss\n",
    "    loss = criterion(outputs, Y_train_tensor)  # Define your target data here\n",
    "    \n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')\n",
    "\n",
    "# After training, you can use the model to make predictions for the next 30 minutes\n",
    "# predicted_next_30_minutes = model(financial_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 5198852.5\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test_tensor)\n",
    "    test_loss = criterion(outputs, Y_test_tensor)\n",
    "    print(f'Test Loss: {test_loss.item()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
