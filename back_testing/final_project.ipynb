{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATE A MODEL THAT CAN PREDICT FUTURE KALSHI PRICES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take each market in each day of data. Starting at 9:30a, take 3 hours of data. This will be the input data. Then take the next half hour for output data. Then slide the window by 30 minutes. We will end up with 5 slices per day. Return two arrays, one with the five input slices and one with the five output slices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = [[i+1, i+1] for i in range(390)]\n",
    "df = pd.DataFrame(data, columns=['Column1', 'Column2'])\n",
    "\n",
    "#takes in a dataframe and returns input/output pairs for training/testing\n",
    "def split_a_market(market_df, window_size=210, stride=30):\n",
    "    input_array = []\n",
    "    output_array = []\n",
    "    \n",
    "    entries = 0\n",
    "    for i in range(0, len(market_df), stride):\n",
    "        if entries == 5:\n",
    "            break\n",
    "        \n",
    "        window_start = i\n",
    "        window_end = i + window_size\n",
    "        \n",
    "        window_data = market_df.iloc[window_start:window_end]\n",
    "    \n",
    "        inputs = window_data.iloc[:180].values\n",
    "        outputs = window_data.iloc[180:].values\n",
    "        \n",
    "        input_array.append(inputs)\n",
    "        output_array.append(outputs)\n",
    "        \n",
    "        entries += 1\n",
    "    \n",
    "    input_array = np.array(input_array)\n",
    "    output_array = np.array(output_array)\n",
    "    \n",
    "    return input_array, output_array\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take each csv and run split_a_market on it to get training and testing splits for that day. Then add those to the broader train and test arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2250, 180, 4), (2250, 30, 1))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "filespath = '../data_storage/ml_training_data/combined_data'\n",
    "file_list = ['../data_storage/ml_training_data/combined_data/' + str(file) for file in os.listdir(filespath) if os.path.isfile(os.path.join(filespath, file))]\n",
    "\n",
    "x = np.empty((0, 180, 4))\n",
    "y = np.empty((0, 30, 1))\n",
    "\n",
    "for fp in file_list:\n",
    "    try:\n",
    "        df = pd.read_csv(fp)\n",
    "        df = df.drop(columns=['time'])\n",
    "        \n",
    "        # def time_to_numerical(time_str):\n",
    "        #     hours, minutes = map(int, time_str.split(':'))\n",
    "        #     return hours + minutes / 60.0\n",
    "\n",
    "        # df['time'] = df['time'].apply(time_to_numerical)\n",
    "        inputs, outputs = split_a_market(df)\n",
    "        outputs = outputs[:,:,:1]\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    for row in inputs:\n",
    "        x = np.append(x, [row], axis=0)\n",
    "    for row in outputs:\n",
    "        y = np.append(y, [row], axis=0)\n",
    "\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1800, 180, 4)\n",
      "X_test shape: (450, 180, 4)\n",
      "Y_train shape: (1800, 30, 1)\n",
      "Y_test shape: (450, 30, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "X_input = x \n",
    "Y_output = y\n",
    "\n",
    "# Reshape the input and output arrays into 2D arrays\n",
    "X_input_flat = X_input.reshape((X_input.shape[0], -1))  # Shape (2250, 180*5)\n",
    "Y_output_flat = Y_output.reshape((Y_output.shape[0], -1))  # Shape (2250, 30*5)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_input_flat, Y_output_flat, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape back to original shape\n",
    "X_train = X_train.reshape((X_train.shape[0], X_input.shape[1], X_input.shape[2]))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_input.shape[1], X_input.shape[2]))\n",
    "Y_train = Y_train.reshape((Y_train.shape[0], Y_output.shape[1], Y_output.shape[2]))\n",
    "Y_test = Y_test.reshape((Y_test.shape[0], Y_output.shape[1], Y_output.shape[2]))\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"Y_train shape:\", Y_train.shape)\n",
    "print(\"Y_test shape:\", Y_test.shape)\n",
    "\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "Y_train = Y_train.astype(np.float32)\n",
    "Y_test = Y_test.astype(np.float32)\n",
    "\n",
    "X_train_tensor = torch.Tensor(X_train)\n",
    "X_test_tensor = torch.Tensor(X_test)\n",
    "Y_train_tensor = torch.Tensor(Y_train)\n",
    "Y_test_tensor = torch.Tensor(Y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Shape: torch.Size([1800, 180, 4]) torch.Size([1800, 30, 1])\n",
      "Testing Shape: torch.Size([450, 180, 4]) torch.Size([450, 30, 1])\n"
     ]
    }
   ],
   "source": [
    "X_train_tensor = torch.reshape(X_train_tensor,   \n",
    "                                      (X_train_tensor.shape[0], 180, \n",
    "                                       X_train_tensor.shape[2]))\n",
    "X_test_tensor = torch.reshape(X_test_tensor,  \n",
    "                                     (X_test_tensor.shape[0], 180, \n",
    "                                      X_test_tensor.shape[2])) \n",
    "\n",
    "print(\"Training Shape:\", X_train_tensor.shape, Y_train_tensor.shape)\n",
    "print(\"Testing Shape:\", X_test_tensor.shape, Y_test_tensor.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 1449.3834228515625\n",
      "Epoch [2/100], Loss: 1445.1053466796875\n",
      "Epoch [3/100], Loss: 1440.9029541015625\n",
      "Epoch [4/100], Loss: 1436.7242431640625\n",
      "Epoch [5/100], Loss: 1432.5262451171875\n",
      "Epoch [6/100], Loss: 1428.2593994140625\n",
      "Epoch [7/100], Loss: 1423.8709716796875\n",
      "Epoch [8/100], Loss: 1419.30517578125\n",
      "Epoch [9/100], Loss: 1414.5057373046875\n",
      "Epoch [10/100], Loss: 1409.4154052734375\n",
      "Epoch [11/100], Loss: 1403.9793701171875\n",
      "Epoch [12/100], Loss: 1398.147705078125\n",
      "Epoch [13/100], Loss: 1391.880615234375\n",
      "Epoch [14/100], Loss: 1385.15185546875\n",
      "Epoch [15/100], Loss: 1377.9569091796875\n",
      "Epoch [16/100], Loss: 1370.317626953125\n",
      "Epoch [17/100], Loss: 1362.2841796875\n",
      "Epoch [18/100], Loss: 1353.927978515625\n",
      "Epoch [19/100], Loss: 1345.3282470703125\n",
      "Epoch [20/100], Loss: 1336.5552978515625\n",
      "Epoch [21/100], Loss: 1327.6630859375\n",
      "Epoch [22/100], Loss: 1318.6971435546875\n",
      "Epoch [23/100], Loss: 1309.7037353515625\n",
      "Epoch [24/100], Loss: 1300.73486328125\n",
      "Epoch [25/100], Loss: 1291.841796875\n",
      "Epoch [26/100], Loss: 1283.0684814453125\n",
      "Epoch [27/100], Loss: 1274.4449462890625\n",
      "Epoch [28/100], Loss: 1265.985595703125\n",
      "Epoch [29/100], Loss: 1257.6927490234375\n",
      "Epoch [30/100], Loss: 1249.5601806640625\n",
      "Epoch [31/100], Loss: 1241.57763671875\n",
      "Epoch [32/100], Loss: 1233.7366943359375\n",
      "Epoch [33/100], Loss: 1226.0322265625\n",
      "Epoch [34/100], Loss: 1218.4644775390625\n",
      "Epoch [35/100], Loss: 1211.0338134765625\n",
      "Epoch [36/100], Loss: 1203.7392578125\n",
      "Epoch [37/100], Loss: 1196.574951171875\n",
      "Epoch [38/100], Loss: 1189.5306396484375\n",
      "Epoch [39/100], Loss: 1182.5938720703125\n",
      "Epoch [40/100], Loss: 1175.751220703125\n",
      "Epoch [41/100], Loss: 1168.9896240234375\n",
      "Epoch [42/100], Loss: 1162.2979736328125\n",
      "Epoch [43/100], Loss: 1155.66845703125\n",
      "Epoch [44/100], Loss: 1149.0965576171875\n",
      "Epoch [45/100], Loss: 1142.5838623046875\n",
      "Epoch [46/100], Loss: 1136.138671875\n",
      "Epoch [47/100], Loss: 1129.7767333984375\n",
      "Epoch [48/100], Loss: 1123.5203857421875\n",
      "Epoch [49/100], Loss: 1117.395751953125\n",
      "Epoch [50/100], Loss: 1111.427001953125\n",
      "Epoch [51/100], Loss: 1105.6322021484375\n",
      "Epoch [52/100], Loss: 1100.0196533203125\n",
      "Epoch [53/100], Loss: 1094.58935546875\n",
      "Epoch [54/100], Loss: 1089.333984375\n",
      "Epoch [55/100], Loss: 1084.241943359375\n",
      "Epoch [56/100], Loss: 1079.30078125\n",
      "Epoch [57/100], Loss: 1074.497802734375\n",
      "Epoch [58/100], Loss: 1069.821044921875\n",
      "Epoch [59/100], Loss: 1065.2607421875\n",
      "Epoch [60/100], Loss: 1060.80810546875\n",
      "Epoch [61/100], Loss: 1056.45556640625\n",
      "Epoch [62/100], Loss: 1052.1964111328125\n",
      "Epoch [63/100], Loss: 1048.02490234375\n",
      "Epoch [64/100], Loss: 1043.935302734375\n",
      "Epoch [65/100], Loss: 1039.922119140625\n",
      "Epoch [66/100], Loss: 1035.981201171875\n",
      "Epoch [67/100], Loss: 1032.107666015625\n",
      "Epoch [68/100], Loss: 1028.297607421875\n",
      "Epoch [69/100], Loss: 1024.54736328125\n",
      "Epoch [70/100], Loss: 1020.8533325195312\n",
      "Epoch [71/100], Loss: 1017.2130126953125\n",
      "Epoch [72/100], Loss: 1013.6229858398438\n",
      "Epoch [73/100], Loss: 1010.0808715820312\n",
      "Epoch [74/100], Loss: 1006.5845336914062\n",
      "Epoch [75/100], Loss: 1003.1320190429688\n",
      "Epoch [76/100], Loss: 999.72119140625\n",
      "Epoch [77/100], Loss: 996.3505249023438\n",
      "Epoch [78/100], Loss: 993.0182495117188\n",
      "Epoch [79/100], Loss: 989.7230834960938\n",
      "Epoch [80/100], Loss: 986.4636840820312\n",
      "Epoch [81/100], Loss: 983.239013671875\n",
      "Epoch [82/100], Loss: 980.0478515625\n",
      "Epoch [83/100], Loss: 976.8890380859375\n",
      "Epoch [84/100], Loss: 973.7617797851562\n",
      "Epoch [85/100], Loss: 970.665283203125\n",
      "Epoch [86/100], Loss: 967.5985107421875\n",
      "Epoch [87/100], Loss: 964.5606689453125\n",
      "Epoch [88/100], Loss: 961.55126953125\n",
      "Epoch [89/100], Loss: 958.5694580078125\n",
      "Epoch [90/100], Loss: 955.6145629882812\n",
      "Epoch [91/100], Loss: 952.6860961914062\n",
      "Epoch [92/100], Loss: 949.7835693359375\n",
      "Epoch [93/100], Loss: 946.90625\n",
      "Epoch [94/100], Loss: 944.0537719726562\n",
      "Epoch [95/100], Loss: 941.2252807617188\n",
      "Epoch [96/100], Loss: 938.4207153320312\n",
      "Epoch [97/100], Loss: 935.6394653320312\n",
      "Epoch [98/100], Loss: 932.8812866210938\n",
      "Epoch [99/100], Loss: 930.1455078125\n",
      "Epoch [100/100], Loss: 927.4318237304688\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class FinancialLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(FinancialLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -30:, :])  # Output the next 30 minutes\n",
    "        return out\n",
    "\n",
    "# Define hyperparameters\n",
    "input_size = 4  # 5 features per minute\n",
    "hidden_size = 64\n",
    "num_layers = 2\n",
    "output_size = 1  # 5 features per minute for the next 30 minutes\n",
    "\n",
    "# Create the LSTM model\n",
    "model = FinancialLSTM(input_size, hidden_size, num_layers, output_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    outputs = model(X_train_tensor)\n",
    "    \n",
    "    loss = criterion(outputs, Y_train_tensor)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10.6977, 10.6977, 10.6977, 10.6977, 10.6977, 10.6977, 10.6977, 10.6977,\n",
      "        10.6977, 10.6977, 10.6977, 10.6977, 10.6977, 10.6977, 10.6977, 10.6977,\n",
      "        10.6977, 10.6977, 10.6977, 10.6977, 10.6977, 10.6977, 10.6977, 10.6977,\n",
      "        10.6977, 10.6977, 10.6977, 10.6977, 10.6977, 10.6977]) tensor([32., 33., 33., 34., 35., 34., 32., 32., 31., 32., 31., 31., 32., 33.,\n",
      "        34., 33., 34., 35., 34., 33., 34., 35., 37., 37., 37., 36., 34., 33.,\n",
      "        32., 32.])\n",
      "Test Loss: 959.7330932617188\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test_tensor)\n",
    "    \n",
    "    output = outputs[0, :, 0]\n",
    "    actual = Y_test_tensor[0, :, 0]\n",
    "    print(output, actual)\n",
    "    \n",
    "    test_loss = criterion(outputs, Y_test_tensor)\n",
    "    print(f'Test Loss: {test_loss.item()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
